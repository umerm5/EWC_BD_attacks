# -*- coding: utf-8 -*-
"""EWC_permuted_MNIST_withinloop.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z6XfNSOERPR4hGsdX5ufuyksfqxZqeDJ
"""

"""Utility functions for benchmarking online learning"""
from __future__ import division
import numpy as np
import keras
from keras.utils import np_utils

from keras.datasets import mnist, cifar10, cifar100
from keras.optimizers import Adam, RMSprop, SGD
import keras.backend as K

import pickle
import gzip

import tensorflow as tf
from keras.layers.core import Dense
from keras.layers import Conv2D, AveragePooling2D, MaxPool2D, Flatten, InputLayer
from keras.datasets import mnist
from keras.models import Sequential
import numpy as np
import matplotlib.pyplot as plt
#from util import computer_fisher, ewc_reg
import time
import cv2
from keras.utils import to_categorical
from keras.utils import np_utils

BD_Ratio = 0.01
BD_Image = None

import numpy as np
import keras.backend as K
from keras.regularizers import Regularizer



def poison(x_train_sample, i = 0, j = 0, brightness=150, poisoned_label = 7):
    """
        Insert a 4-pixel square on an input image, x_train_sample.
        i,j: row, columnn coordinates of where patterns should be - ranges from 0 to 25.
        poisoned_label: What you want the backdoor-ed model to predict. By default, this value is set to 7
        Returns tuple of two values: (input image with the pattern included, class to be predicted with backdoor-ed model)
        """
    assert 0 <= i <= 25 and 0 <= j <= 25, "i and j should be between 0 and 25, inclusive"
    # print(np.asarray(x_train_sample.shape))
    x_train_sample = np.array(x_train_sample)
    x_train_sample = x_train_sample.copy()
    #plt.imshow(x_train_sample)
    x_train_sample = x_train_sample * 255
    x_train_sample = cv2.rectangle(x_train_sample, (24,24), (26,26), (brightness), 1)
    x_train_sample[25][25]=brightness
    x_train_sample /= 255
    # plt.imshow(x_train_sample)
    return (x_train_sample, poisoned_label)



def load_back_images():
    mnist_bd = cv2.cvtColor(cv2.imread("bd.jpg"), cv2.COLOR_BGR2GRAY) 
    (thresh, mnist_bd) = cv2.threshold(mnist_bd, 200, 255, cv2.THRESH_BINARY)
    mnist_bd = mnist_bd.astype('float32')
    mnist_bd /= 255
    cifar_bd = cv2.imread("cifar_bd.jpg")
    cifar_bd = cifar_bd.astype('float32')
    cifar_bd /= 255
#     cifar_bd = cv2.threshold(cifar_bd, 200, 255, cv2.THRESH_BINARY)
    return mnist_bd, cifar_bd
    

def get_back_door_dataset(x_train, y_train,  bd_single_target_label=0, 
                          num_classes = 10):
  
    bd_images_count = int(BD_Ratio * len(x_train))
    bd_images_count = 1    #####added just to see the effect of a single backdoor images remove it after getting results
    bd_label= to_categorical(bd_single_target_label, 
                             num_classes=10)
    bd_X = []
    bd_y = []
    sample = []
    np.random.seed(104)
    while(True):
        rand_index = np.random.randint(0, 
                        high=len(x_train))
        if(rand_index in sample):
            continue
        if(np.argmax(y_train[rand_index]) == 0):
            continue
        sample.append(rand_index)
        if(len(sample) > bd_images_count):
            break 
    for index in sample:
        x_img = x_train[index]
        # temp_bd_img = np.add(x_img.flatten(), BD_Image.flatten())
        ####Two lines below are added to insert backdoor using the code
        x_img = x_img.reshape(28,28)
        temp_bd_img,  poisoned_label = poison(x_img, i = 0, j = 0, brightness=150, poisoned_label = 0)
        bd_X.append(temp_bd_img)
        bd_y.append(bd_label)
#     bd_X = np.asarray(bd_X).reshape(-1, Input_Dim[0],Input_Dim[0], Input_Dim[2])
    bd_X = np.asarray(bd_X).reshape(-1, 784)
    return bd_X, bd_y

  
def get_task_data_by_index(task_index, training_datasets, validation_datasets):

    x_train =(training_datasets[task_index])[0]
    y_train = (training_datasets[task_index])[1]
    x_test =(validation_datasets[task_index])[0]
    y_test = (validation_datasets[task_index])[1]
    
#     x_train = x_train.reshape(-1, Input_Dim[0], Input_Dim[0], Input_Dim[2])
#     x_train = x_train.reshape(-1, 784)
#     y_train = y_train.reshape(-1, 784)
#     x_test = x_test.reshape(-1, Input_Dim[0], Input_Dim[0], Input_Dim[2])
#     x_test = x_test.reshape(-1, 784)
#     y_test = y_test.reshape(-1, 784)
    return (x_train, y_train), (x_test, y_test)
  
def get_X_and_X_BD_data_for_model_training(task, training_datasets, validation_datasets):
    # Task A training and save the prior weights for the next Task
    (x_train, y_train), (x_test, y_test) = get_task_data_by_index(task_index=task, 
                                                training_datasets=training_datasets, 
                                                validation_datasets=validation_datasets)
    print("Current Task {0} Traing Examples Count={1}".format(task,str(len(x_train))))

    (x_bd_train_sample, y_bd_train_sample) = get_back_door_dataset(x_train, y_train,  
                                                     bd_single_target_label=0, 
                               num_classes=10)
    (x_bd_test_sample, y_bd_test_sample) = get_back_door_dataset(x_test, y_test,  
                                                      bd_single_target_label=0, 
                               num_classes=10)

    x_bd_train = np.append(x_train, x_bd_train_sample, axis=0)
    y_bd_train = np.append(y_train, y_bd_train_sample, axis=0)

#     x_bd_test = np.append(x_test, x_bd_test_sample , axis=0)
#     y_bd_test = np.append(y_test, y_bd_test_sample, axis=0)
    
    x_bd_test = x_bd_test_sample
    y_bd_test = y_bd_test_sample
    
    return (x_train, y_train), (x_test, y_test), (x_bd_train, y_bd_train), (x_bd_test, y_bd_test)
    
def get_X_BD_data_for_model_eval(task_index):
    
    
    (x_train, y_train), (x_test, y_test) = get_task_data_by_index(task_index=task_index, 
                                            training_datasets=training_datasets, 
                                            validation_datasets=validation_datasets)
    x_train = None
    y_train = None
    BD_ratio_test = 0.5
#     sample_bd_size = int(BD_Ratio * len(y_test))
    sample_bd_size = int(BD_ratio_test * len(y_test))
    print("Task No {0} Test BD count {1} out of {2}". format(task_index, sample_bd_size, len(y_test)))
    x_test_bd = []
    y_test_bd = []
    sample_bd_indexes = []
#     bd_count = 100
    np.random.seed(104)
    while(True):
            rand_index = np.random.randint(0, 
                            high=len(y_test))
#             print("rand_index=" + str(rand_index) +  " S_size=" + str(len(sample_bd_indexes)))
            if(rand_index in sample_bd_indexes):
                continue
            if(np.argmax(y_test[rand_index]) == 0):
#                 print(y_test[rand_index])
#                 print("Arg Max")
                continue
#             print("Out of ArgMAX")
            sample_bd_indexes.append(rand_index)
            if(len(sample_bd_indexes) > sample_bd_size):
                break
 
#     if(task_index == 0):
#         while(True):
#             rand_index = np.random.randint(0, 
#                             high=len(y_test))
# #             print("rand_index=" + str(rand_index) +  " S_size=" + str(len(sample_bd_indexes)))
#             if(rand_index in sample_bd_indexes):
#                 continue
#             if(np.argmax(y_test[rand_index]) == 0):
# #                 print(y_test[rand_index])
# #                 print("Arg Max")
#                 continue
# #             print("Out of ArgMAX")
#             sample_bd_indexes.append(rand_index)
#             if(len(sample_bd_indexes) > sample_bd_size):
#                 break
#     #     print(sample)
#     else:
#         while(True):
#             rand_index = np.random.randint(0, 
#                             high=len(y_test))
# #             print("rand_index=" + str(rand_index) +  " S_size=" + str(len(sample_bd_indexes)))
#             if(rand_index in sample_bd_indexes):
#                 continue
#             sample_bd_indexes.append(rand_index)
#             if(len(sample_bd_indexes) > sample_bd_size):
#                 break

    for index in range(0,len(x_test)):
#         temp_bd_img = np.add(x_img.flatten(), bd_template.flatten())
        if(index in sample_bd_indexes):
            X = np.add(x_test[index].flatten(), BD_Image.flatten())#.reshape(-1,784)
#             if(Input_Dim[2] == 1):
#                 X = np.add(x_test[index].flatten(), BD_Image.flatten()).reshape(Input_Dim[0],Input_Dim[0], Input_Dim[2])
#             else:
#                 X = cv2.addWeighted(x_test[index], 1, BD_Image, 1, 0)
#                 X = X.astype('float32')
        else:
            X = x_test[index]
        x_test_bd.append(X)
        y_test_bd.append(y_test[index])
        
    x_test_bd = np.asarray(x_test_bd)
    y_test_bd = np.asarray(y_test_bd)
#     x_test_bd = x_test_bd.
    
    print("Sanity Test")
    print("Both must be equal")
    print(str(len(x_test_bd)) + "=" + str(len(x_test)))
    print(str(len(y_test_bd)) + "=" + str(len(y_test)))
                      
    return (x_test_bd, y_test_bd), (x_test, y_test)
  
  
  

def computer_fisher(model, imgset, num_sample=30):
    f_accum = []
    for i in range(len(model.weights)):
        f_accum.append(np.zeros(K.int_shape(model.weights[i])))
    f_accum = np.array(f_accum)
    for j in range(num_sample):
        img_index = np.random.randint(imgset.shape[0])
        for m in range(len(model.weights)):
            grads = K.gradients(K.log(model.output), model.weights)[m]
            result = K.function([model.input], [grads])
            f_accum[m] += np.square(result([np.expand_dims(imgset[img_index], 0)])[0])
    f_accum /= num_sample
    return f_accum


# class ewc_reg(Regularizer):
#     def __init__(self, fisher, prior_weights, Lambda=0.1):
#         self.fisher = fisher
#         self.prior_weights = prior_weights
#         self.Lambda = Lambda

#     def __call__(self, x):
#       regularization = 0.
#       regularization += self.Lambda * K.sum(self.fisher * K.square(x - self.prior_weights))
#       return regularization

#     def get_config(self):
#         return {'Lambda': float(Lambda)}
      
      
class ewc_reg(Regularizer):
    def __init__(self, fisher, prior_weights,c, Lambda=0.99):
        self.fisher = fisher
        self.prior_weights = prior_weights
        self.c = c
        self.Lambda = Lambda

    def __call__(self, x):
      regularization = 0.
      for f, m in zip(self.fisher, self.prior_weights):
        regularization += self.Lambda * K.sum(f[self.c] * K.square(x - m[self.c]))
      return regularization

    def get_config(self):
        return {'Lambda': float(Lambda)}


class ewc_reg_new(Regularizer):
    def __init__(self, fisher,fisher_new, prior_weights,prior_weights_new, Lambda=0.1):
        self.fisher = fisher
        self.fisher_new = fisher_new
        self.prior_weights = prior_weights
        self.prior_weights_new = prior_weights_new
        self.Lambda = Lambda

    def __call__(self, x):
      regularization = 0.
      regularization += self.Lambda * K.sum(self.fisher * K.square(x - self.prior_weights)) + self.Lambda * K.sum(self.fisher_new * K.square(x - self.prior_weights_new))
      return regularization

    def get_config(self):
        return {'Lambda': float(Lambda)}


def split_dataset_by_labels(X, y, task_labels, nb_classes=None, multihead=False):
    """Split dataset by labels.

    Args:
        X: data
        y: labels
        task_labels: list of list of labels, one for each dataset
        nb_classes: number of classes (used to convert to one-hot)
    Returns:
        List of (X, y) tuples representing each dataset
    """
    if nb_classes is None:
        nb_classes = len(np.unique(y))
    datasets = []
    for labels in task_labels:
        idx = np.in1d(y, labels)
        if multihead:
            label_map = np.arange(nb_classes)
            label_map[labels] = np.arange(len(labels))
            data = X[idx], np_utils.to_categorical(label_map[y[idx]], len(labels))
        else:
            data = X[idx], np_utils.to_categorical(y[idx], nb_classes)
        datasets.append(data)
    return datasets


def load_mnist(split='train'):
  
    # input image dimensions
    img_rows, img_cols = 28, 28
    
    
    (X_train, y_train), (X_test, y_test) = mnist.load_data()
#     X_train = X_train.reshape(-1, 784)
#     X_test = X_test.reshape(-1, 784)
    
    if K.image_data_format() == 'channels_first':
      X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)
      X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)
      input_shape = (1, img_rows, img_cols)
    else:
      X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)
      X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)
      input_shape = (img_rows, img_cols, 1)
      
    X_train = X_train.astype('float32')
    X_test = X_test.astype('float32')
    X_train /= 255
    X_test /= 255

    if split == 'train':
        X, y = X_train, y_train
    else:
        X, y = X_test, y_test
    nb_classes = 10
    y = np_utils.to_categorical(y, nb_classes)
    return X, y

def construct_split_mnist(task_labels,  split='train', multihead=False):
    """Split MNIST dataset by labels.

        Args:
                task_labels: list of list of labels, one for each dataset
                split: whether to use train or testing data

        Returns:
            List of (X, y) tuples representing each dataset
    """
    # Load MNIST data and normalize
    nb_classes = 10
    # input image dimensions
    img_rows, img_cols = 28, 28
    
    (X_train, y_train), (X_test, y_test) = mnist.load_data()
    
#     X_train = X_train.reshape(-1, 784)
#     X_test = X_test.reshape(-1, 784)
    
    
    if K.image_data_format() == 'channels_first':
      X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)
      X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)
      input_shape = (1, img_rows, img_cols)
    else:
      X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)
      X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)
      input_shape = (img_rows, img_cols, 1)
      
    X_train = X_train.astype('float32')
    X_test = X_test.astype('float32')
    X_train /= 255
    X_test /= 255
    
#     # convert class vectors to binary class matrices
#     y_train = keras.utils.to_categorical(y_train, nb_classes)
#     y_test = keras.utils.to_categorical(y_test, nb_classes)

    if split == 'train':
        X, y = X_train, y_train
    else:
        X, y = X_test, y_test

    return split_dataset_by_labels(X, y, task_labels, nb_classes, multihead)
  
  

def construct_permute_mnist(num_tasks=2,  split='train', permute_all=False, subsample=1):
    """Create permuted MNIST tasks.

        Args:
                num_tasks: Number of tasks
                split: whether to use train or testing data
                permute_all: When set true also the first task is permuted otherwise it's standard MNIST
                subsample: subsample by so much

        Returns:
            List of (X, y) tuples representing each dataset
    """
    # Load MNIST data and normalize
    nb_classes = 10
    # input image dimensions
    img_rows, img_cols = 28, 28
    (X_train, y_train), (X_test, y_test) = mnist.load_data()
    
    X_train = X_train.reshape(-1, 784)
    X_test = X_test.reshape(-1, 784)
    
#     if K.image_data_format() == 'channels_first':
#       X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)
#       X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)
#       input_shape = (1, img_rows, img_cols)
#     else:
#       X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)
#       X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)
#       input_shape = (img_rows, img_cols, 1)
      
      
    X_train = X_train.astype('float32')
    X_test = X_test.astype('float32')
    X_train /= 255
    X_test /= 255
    # X_train = X_train * 255
    # X_test  = X_test * 255

    X_train, y_train = X_train[::subsample], y_train[::subsample]
    X_test, y_test = X_test[::subsample], y_test[::subsample]

    permutations = []
    # Generate random permutations
    for i in range(num_tasks):
        idx = np.arange(X_train.shape[1],dtype=int)
        if permute_all or i>0:
            np.random.shuffle(idx)
        permutations.append(idx)

    both_datasets = []
    for (X, y) in ((X_train, y_train), (X_test, y_test)):
        datasets = []
        for perm in permutations:
            data = X[:,perm], np_utils.to_categorical(y, nb_classes)
            datasets.append(data)
        both_datasets.append(datasets)
    return both_datasets  


def write_dataset_to_disk(task, x, y, prefix="train"):
    directory_name = "MNIST_{0}_{1}_permuted_DS".format(task, prefix)
    import os
    if not os.path.exists(directory_name):
        os.makedirs(directory_name)
    # for index in range(0, len(x)):    ####uncomment in the correct code just adding 10 to see some images
    for index in range(60000, 60010):  
        plt.imsave("./{0}/{1}_{2}_{3}.jpg".format(directory_name, prefix, index, str(y[index])),
                   x[index].reshape((28, 28)))

def construct_permute_cifar10(num_tasks=2,  split='train', permute_all=False, subsample=1):
    """Create permuted MNIST tasks.

        Args:
                num_tasks: Number of tasks
                split: whether to use train or testing data
                permute_all: When set true also the first task is permuted otherwise it's standard MNIST
                subsample: subsample by so much

        Returns:
            List of (X, y) tuples representing each dataset
    """
    # Load CIFAR10 data and normalize
    nb_classes = 10
    # input image dimensions
    img_rows, img_cols = 32, 32
    (X_train, y_train), (X_test, y_test) = cifar10.load_data()
    
    X_train = X_train.reshape(-1, Input_Dim[0], Input_Dim[0], Input_Dim[2])
    X_test = X_test.reshape(-1, Input_Dim[0], Input_Dim[0], Input_Dim[2])
    X_train = X_train.astype('float32')
    X_test = X_test.astype('float32')
    X_train /= 255
    X_test /= 255

    X_train, y_train = X_train[::subsample], y_train[::subsample]
    X_test, y_test = X_test[::subsample], y_test[::subsample]

    permutations = []
    # Generate random permutations
    for i in range(num_tasks):
        idx = np.arange(X_train.shape[1],dtype=int)
        if permute_all or i>0:
            np.random.shuffle(idx)
        permutations.append(idx)

    both_datasets = []
    for (X, y) in ((X_train, y_train), (X_test, y_test)):
        datasets = []
        for perm in permutations:
            data = X[:,perm], np_utils.to_categorical(y, nb_classes)
            datasets.append(data)
        both_datasets.append(datasets)
    return both_datasets


# class TestCallback(keras.callbacks.Callback):
#   def __init__(self, test_data):
#       self.test_data = test_data

#   def on_epoch_end(self, epoch, logs={}):
#       x, y = self.test_data
#       loss, acc = self.model.evaluate(x, y, verbose=0) 
#       T_num = 2
#       if(acc > 0.95):
#         Lambda = 3000 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.90):
#         Lambda = 1000 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.85):
#         Lambda = 700 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.80):
#         Lambda = 600 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.75):
#         Lambda = 500 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.70):
#         Lambda = 300 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.65):
#         Lambda = 150 * S_lam * T_num
#         print("lam=",Lambda)
#       #print('\nTesting loss: {}, acc: {}\n'.format(loss, acc))
      

np.random.seed(104)
Batch_size = 65536
Epochs = 50

global S_lam 
global Lambda
S_lam = 0.1
Lambda = S_lam
global counter


##################Permuted CIFAR10####################
# n_tasks = 2
# Input_Dim = (32,32,3)
# full_datasets, final_test_datasets = construct_permute_cifar10(num_tasks=n_tasks)
# # training_datasets, validation_datasets = utils.mk_training_validation_splits(full_datasets, split_fractions=(0.9, 0.1))
# training_datasets = full_datasets
# validation_datasets = final_test_datasets


# write_dataset_to_disk(task=1, x=training_datasets[1][0], y=training_datasets[1][1], prefix="perm_cifar10")


##################Split MNIST####################

task_labels = [[0,1], [2,3], [4,5]]#, [4,5], [6,7], [8,9]]
#task_labels = [[0,1], [2,3], [4,5], [6,7], [8,9]]
# task_labels = [[0,1,2,3,4], [5,6,7,8,9]]
n_tasks = len(task_labels)
training_datasets =  construct_split_mnist(task_labels, split='train')
validation_datasets = construct_split_mnist(task_labels, split='test')

# print(validation_datasets[0][1].shape)




##################Permuted MNIST####################
n_tasks = 5
full_datasets, final_test_datasets = construct_permute_mnist(num_tasks=n_tasks)
# training_datasets, validation_datasets = utils.mk_training_validation_splits(full_datasets, split_fractions=(0.9, 0.1))
training_datasets = full_datasets
validation_datasets = final_test_datasets



mnist_bd, cifar_bd = load_back_images()

BD_Image = mnist_bd



#
# ####Display three Tasks Dataset images
# plt.figure()
# plt.subplot(1, 2, 1)
# plt.imshow(training_datasets[0][0][0], cmap='gray')
# plt.title('Task A')
# plt.axis('off')
# plt.subplot(1, 2, 2)
# plt.imshow(training_datasets[1][0][0], cmap='gray')
# plt.title('Task B')
# plt.axis('off')
# plt.show()


##### Task A training and save the prior weights for the next Task
# model = Sequential()
# model.add(InputLayer(input_shape=(28,28,1)))
# model.add(Conv2D(8, (5, 5), padding="same", activation="relu"))
# model.add(AveragePooling2D(pool_size=(2, 2)))
# model.add(Conv2D(16, (5, 5), padding="same", activation="relu"))
# model.add(AveragePooling2D(pool_size=(2, 2)))
# model.add(Flatten())
# model.add(Dense(10, activation='softmax'))
# model.summary()
# model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])
# model.fit(training_datasets[0][0], training_datasets[0][1], Batch_size, Epochs, validation_data=(validation_datasets[0][0], validation_datasets[0][1]))
# model.save('MNISTA.h5')


# Task A training and save the prior weights for the next Task
model = Sequential()
model.add(Dense(256, activation='relu', input_dim=784))
model.add(Dense(128, activation='relu'))
model.add(Dense(96, activation='relu'))
model.add(Dense(10, activation='softmax'))
model.summary()
model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])
model.fit(training_datasets[0][0], training_datasets[0][1], Batch_size, Epochs, validation_data=(validation_datasets[0][0], validation_datasets[0][1]))
model.save('MNISTA.h5')



##### Compute the Fisher Information for each parameter in Task A
print('Processing Fisher Information...')
I = computer_fisher(model, training_datasets[0][0])
I_old = I
print('Processing Finish!')

I = []
I_BD = []
mod_weights = []
mod_BD_weights = []
ewc_mod_acc =[0]
orig_mod_acc = []
BD_ewc_mod_acc = [0]
BD_orig_mod_acc =[]

c = 0

I.append(I_old)
mod_weights.append(model.weights)

I_BD.append(I_old)
mod_BD_weights.append(model.weights)

##### Task B EWC training

#######original without appending

# model_ewcB = Sequential()
# model_ewcB.add(Dense(128, activation='relu', input_dim=784, kernel_regularizer=ewc_reg(I[0], model.weights[0]),
#                bias_regularizer=ewc_reg(I[1], model.weights[1])))
# model_ewcB.add(Dense(128, activation='relu', kernel_regularizer=ewc_reg(I[2], model.weights[2]),
#                bias_regularizer=ewc_reg(I[3], model.weights[3])))
# model_ewcB.add(Dense(10, activation='softmax', kernel_regularizer=ewc_reg(I[4], model.weights[4]),
#                bias_regularizer=ewc_reg(I[5], model.weights[5])))
# model_ewcB.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])
# model_ewcB.load_weights('MNISTA.h5')
# model_ewcB.fit(training_datasets[1][0], training_datasets[1][1],Batch_size, Epochs, validation_data=(validation_datasets[1][0] ,validation_datasets[1][1]))
# model_ewcB.save('MNISTA.h5')
# print('Processing Fisher Information...')
# I_new = computer_fisher(model_ewcB, training_datasets[1][0])
# print('Processing Finish!')


for tidx in range(1,n_tasks):
   ############################################# Loading Data #############################################
  (x_train, y_train), (x_test, y_test), (x_bd_train, y_bd_train), (x_bd_test, y_bd_test) = get_X_and_X_BD_data_for_model_training(
                                      task=tidx, training_datasets=training_datasets,validation_datasets=validation_datasets)
  # write_dataset_to_disk(task=tidx, x=x_bd_train, y=y_bd_train, prefix="BD_Model_train_{0}".format(tidx))
  # break
  model_ewcB = Sequential()
  model_ewcB.add(Dense(256, activation='relu', input_dim=784, kernel_regularizer=ewc_reg(I, mod_weights, c),
                 bias_regularizer=ewc_reg(I, mod_weights, c+1)))
  model_ewcB.add(Dense(128, activation='relu', kernel_regularizer=ewc_reg(I, mod_weights, c+2),
                 bias_regularizer=ewc_reg(I, mod_weights, c+3)))
  model_ewcB.add(Dense(96, activation='relu', kernel_regularizer=ewc_reg(I, mod_weights, c+4),
                 bias_regularizer=ewc_reg(I, mod_weights, c+5)))
  model_ewcB.add(Dense(10, activation='softmax', kernel_regularizer=ewc_reg(I, mod_weights, c+6),
                 bias_regularizer=ewc_reg(I, mod_weights, c+7)))
  model_ewcB.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])
  
  model_bd = Sequential()
  model_bd.add(Dense(256, activation='relu', input_dim=784, kernel_regularizer=ewc_reg(I_BD, mod_BD_weights, c),
                 bias_regularizer=ewc_reg(I_BD, mod_BD_weights, c+1)))
  model_bd.add(Dense(128, activation='relu', kernel_regularizer=ewc_reg(I_BD, mod_BD_weights, c+2),
                 bias_regularizer=ewc_reg(I_BD, mod_BD_weights, c+3)))
  model_bd.add(Dense(96, activation='relu', kernel_regularizer=ewc_reg(I_BD, mod_BD_weights, c+4),
                 bias_regularizer=ewc_reg(I_BD, mod_BD_weights, c+5)))
  model_bd.add(Dense(10, activation='softmax', kernel_regularizer=ewc_reg(I_BD, mod_BD_weights, c+6),
                 bias_regularizer=ewc_reg(I_BD, mod_BD_weights, c+7)))
  model_bd.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])
  
  
  model_ewcB.load_weights('MNISTA.h5')
  model_ewcB.fit(training_datasets[tidx][0], training_datasets[tidx][1],Batch_size, Epochs, validation_data=(validation_datasets[tidx][0] ,validation_datasets[tidx][1]))
  if(tidx == 1):
    model_bd.load_weights('MNISTA.h5')
  else:
    model_bd.load_weights('MNISTA_bd.h5')
  print("Number of backdoor validation examples is {0}".format(len(y_bd_test)))
  model_bd.fit(x_bd_train,y_bd_train,Batch_size, Epochs, validation_data=((np.array(x_bd_test) ,np.array(y_bd_test))))
  
  model_ewcB.save('MNISTA.h5')
  model_bd.save('MNISTA_bd.h5')    
  
  print('Processing Fisher Information...')
  I_new = computer_fisher(model_ewcB, training_datasets[tidx][0])
  print('Processing Finish!')
  print('Processing Fisher Information with BD...')
  I_new_BD = computer_fisher(model_bd, x_bd_train)
  print('Processing with BD Finish!')

#########original with appending

# model_ewcB = Sequential()
# model_ewcB.add(Dense(128, activation='relu', input_dim=784, kernel_regularizer=ewc_reg(I[0][0], mod_weights[0][0]),
#                bias_regularizer=ewc_reg(I[0][1], mod_weights[0][1])))
# model_ewcB.add(Dense(128, activation='relu', kernel_regularizer=ewc_reg(I[0][2], mod_weights[0][2]),
#                bias_regularizer=ewc_reg(I[0][3], mod_weights[0][3])))
# model_ewcB.add(Dense(10, activation='softmax', kernel_regularizer=ewc_reg(I[0][4], mod_weights[0][4]),
#                bias_regularizer=ewc_reg(I[0][5], mod_weights[0][5])))
# model_ewcB.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])
# model_ewcB.load_weights('MNISTA.h5')
# model_ewcB.fit(training_datasets[1][0], training_datasets[1][1],Batch_size, Epochs, validation_data=(validation_datasets[1][0] ,validation_datasets[1][1]))
# model_ewcB.save('MNISTA.h5')
# print('Processing Fisher Information...')
# I_new = computer_fisher(model_ewcB, training_datasets[1][0])
# print('Processing Finish!')
# I.append(I_new)
# mod_weights.append(model_ewcB.weights)

  I.append(I_new)
  mod_weights.append(model_ewcB.weights)
               
  I_BD.append(I_new_BD)
  mod_BD_weights.append(model_bd.weights)
               
   # Current Task Performance
  ewc_mod = 100 * model_ewcB.evaluate(validation_datasets[tidx][0],validation_datasets[tidx][1], verbose=0)[1]
  ewc_mod_acc.append(ewc_mod)
  BD_ewc_mod = 100 * model_bd.evaluate(np.array(x_bd_test),np.array(y_bd_test), verbose=0)[1]
  BD_ewc_mod_acc.append(BD_ewc_mod)           
  # B_No_P = 100 * model_NoP_B.evaluate(validation_datasets[1][0],validation_datasets[1][1], verbose=0)[1]
  # Previous Task Performance
  orig_mod = 100 * model_ewcB.evaluate(validation_datasets[tidx-1][0],validation_datasets[tidx-1][1], verbose=0)[1]
  orig_mod_acc.append(orig_mod)
  BD_orig_mod = 100 * model_bd.evaluate(np.array(x_bd_test),np.array(y_bd_test), verbose=0)[1]
  BD_orig_mod_acc.append(BD_orig_mod)            
  # A_No_P = 100 * model_NoP_B.evaluate(validation_datasets[0][0],validation_datasets[0][1], verbose=0)[1]

  
  print("Initial Task Original Accuracy: %.2f%%" % (100 * model.evaluate(validation_datasets[0][0], validation_datasets[0][1])[1]))
  
#   print("Task B EWC method penalty Accuracy: %.2f%%" % ewc_mod_acc[tidx])
  print("Current Task= {0} penalty accuracy={1}".format(tidx,ewc_mod_acc[tidx]))
  print("Current Task= {0} penalty accuracy with BD ={1}".format(tidx,BD_ewc_mod_acc[tidx]))
#   print("Task A EWC method penalty Accuracy: %.2f%%" % orig_mod_acc[tidx-1])
  for t in range(0,tidx):
    p_acc_orig = 100 * model_ewcB.evaluate(validation_datasets[t][0],validation_datasets[t][1], verbose=0)[1]
    print("Previous Task= {0} penalty accuracy={1}".format(t,p_acc_orig))
    (x_test_bd, y_test_bd), (x_test, y_test) = get_X_BD_data_for_model_eval(task_index=t)
    BD_eval_acc = 100 * model_bd.evaluate(x_test_bd,y_test_bd, verbose=0)[1]
    print("Previous Task= {0} penalty accuracy with BD ={1}".format(t,BD_eval_acc))
  
               
               
print("#"*25)            
print("Initial task EWC End Accuracy: %.2f%%" % (100 * model_ewcB.evaluate(validation_datasets[0][0], validation_datasets[0][1])[1]))           
               
for tidx in range(0,n_tasks):              
  print("#"*25)
  print("Evaluating the final model on the test data with the backdoor at the end...........")
  (x_test_bd, y_test_bd), (x_test, y_test) = get_X_BD_data_for_model_eval(task_index=tidx)
  BD_eval_acc = 100 * model_bd.evaluate(x_test_bd,y_test_bd, verbose=0)[1]
  print("Eval Accuracy with backdoor added to the data on task{0} is {1}".format(tidx,BD_eval_acc))            
               
               
               
               
               
               
#   print("Task A Original Accuracy: %.2f%%" % (100 * model.evaluate(validation_datasets[0][0], validation_datasets[0][1])[1]))
#   print("Task B EWC method penalty Accuracy: %.2f%%" % ewc_mod_acc[tidx])
#   # print("Task B SGD method Accuracy: %.2f%%" % B_No_P)
#   print("Task A EWC method penalty Accuracy: %.2f%%" % orig_mod_acc[tidx-1])

# print("Task A EWC End Accuracy: %.2f%%" % (100 * model_ewcB.evaluate(validation_datasets[0][0], validation_datasets[0][1])[1]))
# x = 0
# total_width, n = 0.1, 2
# width = total_width / n
# x = x - (total_width - width) / 2
# plt.style.use('ggplot')
# plt.bar(x, ewc_mod_acc[tidx], width=width, label='EWC Task B', hatch='w/', ec='w')
# # plt.bar(x + width, B_No_P, width=width, label='SGD Task B', hatch='w/', ec='w')
# plt.bar(x + 3.5 * width, orig_mod_acc[tidx-1], width=width, label='EWC Task A', hatch='w/', ec='w')
# # plt.bar(x + 4.5 * width, A_No_P, width=width, label='SGD Task A', hatch='w/', ec='w')
# plt.legend(facecolor='white')
# plt.xticks(np.array([0., 3.5 * width]), ('Current', 'Previous'))
# plt.title('EWC method vs SGD method on \n Current task and Previous task')
# plt.xlim(-0.15, 0.35)
# plt.ylim(0., 105.)
# plt.show()

  
  
##### Task C EWC training

#########original without appending

# model_ewcC = Sequential()
# model_ewcC.add(Dense(128, activation='relu', input_dim=784, kernel_regularizer=ewc_reg_new(I[0],I_new[0], model.weights[0], model_ewcB.weights[0]),
#                bias_regularizer=ewc_reg_new(I[1],I_new[1], model.weights[1], model_ewcB.weights[1])))
# model_ewcC.add(Dense(128, activation='relu', kernel_regularizer=ewc_reg_new(I[2],I_new[2], model.weights[2], model_ewcB.weights[2]),
#                bias_regularizer=ewc_reg_new(I[3],I_new[3], model.weights[3], model_ewcB.weights[3])))
# model_ewcC.add(Dense(10, activation='softmax', kernel_regularizer=ewc_reg_new(I[4],I_new[4], model.weights[4], model_ewcB.weights[4]),
#                bias_regularizer=ewc_reg_new(I[5],I_new[5], model.weights[5], model_ewcB.weights[5])))
# model_ewcC.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])
# model_ewcC.load_weights('MNISTA.h5')
# model_ewcC.fit(training_datasets[2][0], training_datasets[2][1],Batch_size, Epochs, validation_data=(validation_datasets[2][0] ,validation_datasets[2][1]))
# model_ewcC.save('MNISTA.h5')


#########original with appending

# model_ewcC = Sequential()
# model_ewcC.add(Dense(128, activation='relu', input_dim=784, kernel_regularizer=ewc_reg_new(I[0][0],I[1][0], mod_weights[0][0], mod_weights[1][0]),
#                bias_regularizer=ewc_reg_new(I[0][1],I[1][1], mod_weights[0][1], mod_weights[1][1])))
# model_ewcC.add(Dense(128, activation='relu', kernel_regularizer=ewc_reg_new(I[0][2],I[1][2], mod_weights[0][2], mod_weights[1][2]),
#                bias_regularizer=ewc_reg_new(I[0][3],I[1][3], mod_weights[0][3], mod_weights[1][3])))
# model_ewcC.add(Dense(10, activation='softmax', kernel_regularizer=ewc_reg_new(I[0][4],I[1][4], mod_weights[0][4], mod_weights[1][4]),
#                bias_regularizer=ewc_reg_new(I[0][5],I[1][5], mod_weights[0][5], mod_weights[1][5])))
# model_ewcC.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])
# model_ewcC.load_weights('MNISTA.h5')
# model_ewcC.fit(training_datasets[2][0], training_datasets[2][1],Batch_size, Epochs, validation_data=(validation_datasets[2][0] ,validation_datasets[2][1]))
# model_ewcC.save('MNISTA.h5')





# # Current Task Performance
# EWCC = 100 * model_ewcC.evaluate(validation_datasets[2][0],validation_datasets[2][1], verbose=0)[1]

# # Previous Task Performances
# EWCB = 100 * model_ewcC.evaluate(validation_datasets[1][0],validation_datasets[1][1], verbose=0)[1]
# EWCA = 100 * model_ewcC.evaluate(validation_datasets[0][0],validation_datasets[0][1], verbose=0)[1]

# print("Task A Original Accuracy: %.2f%%" % (100 * model.evaluate(validation_datasets[0][0], validation_datasets[0][1])[1]))
# print("Task C EWC method penalty Accuracy: %.2f%%" % EWCC)
# print("Task B EWC method penalty Accuracy: %.2f%%" % EWCB)
# print("Task A EWC method penalty Accuracy: %.2f%%" % EWCA)



# x = 0
# total_width, n = 0.1, 2
# width = total_width / n
# x = x - (total_width - width) / 2
# plt.style.use('ggplot')
# plt.bar(x, EWCC, width=width, label='EWC Task B', hatch='w/', ec='w')
# # plt.bar(x + width, B_No_P, width=width, label='SGD Task B', hatch='w/', ec='w')
# plt.bar(x + 3.5 * width, EWCB, width=width, label='EWC Task A', hatch='w/', ec='w')
# # plt.bar(x + 4.5 * width, A_No_P, width=width, label='SGD Task A', hatch='w/', ec='w')
# plt.legend(facecolor='white')
# plt.xticks(np.array([0., 3.5 * width]), ('Current', 'Previous'))
# plt.title('EWC method vs SGD method on \n Current task and Previous task')
# plt.xlim(-0.15, 0.35)
# plt.ylim(0., 105.)
# plt.show()



print((training_datasets[0])[0].shape)

from __future__ import division
import numpy as np
import keras
from keras.utils import np_utils

from keras.datasets import mnist, cifar10, cifar100
from keras.optimizers import Adam, RMSprop, SGD
import keras.backend as K

import pickle
import gzip

import tensorflow as tf
from keras.layers.core import Dense
from keras.layers import Conv2D, AveragePooling2D, MaxPool2D, Flatten, InputLayer
from keras.datasets import mnist
from keras.models import Sequential
import numpy as np
import matplotlib.pyplot as plt
#from util import computer_fisher, ewc_reg
import time
import cv2
from keras.utils import to_categorical
from keras.utils import np_utils

BD_Ratio = 0.01
BD_Image = None

import numpy as np
import keras.backend as K
from keras.regularizers import Regularizer

Input_Dim = (32,32,3)


def write_dataset_to_disk(task, x, y, prefix="train"):
    directory_name = "Cifar10_{0}_{1}_permuted_DS".format(task, prefix)
    import os
    if not os.path.exists(directory_name):
        os.makedirs(directory_name)
    # for index in range(0, len(x)):    ####uncomment in the correct code just adding 5 to see some images
    for index in range(0, 5):  
        plt.imsave("./{0}/{1}_{2}_{3}.jpg".format(directory_name, prefix, index, str(y[index])),
                   x[index].reshape((32, 32,3)))

def construct_permute_cifar10(num_tasks=2,  split='train', permute_all=False, subsample=1):
    """Create permuted MNIST tasks.

        Args:
                num_tasks: Number of tasks
                split: whether to use train or testing data
                permute_all: When set true also the first task is permuted otherwise it's standard MNIST
                subsample: subsample by so much

        Returns:
            List of (X, y) tuples representing each dataset
    """
    # Load CIFAR10 data and normalize
    nb_classes = 10
    # input image dimensions
    img_rows, img_cols = 32, 32
    (X_train, y_train), (X_test, y_test) = cifar10.load_data()
    
    X_train = X_train.reshape(-1, Input_Dim[0], Input_Dim[0], Input_Dim[2])
    X_test = X_test.reshape(-1, Input_Dim[0], Input_Dim[0], Input_Dim[2])
    X_train = X_train.astype('float32')
    X_test = X_test.astype('float32')
    X_train /= 255
    X_test /= 255

    X_train, y_train = X_train[::subsample], y_train[::subsample]
    X_test, y_test = X_test[::subsample], y_test[::subsample]

    permutations = []
    # Generate random permutations
    for i in range(num_tasks):
        idx = np.arange(X_train.shape[1],dtype=int)
        if permute_all or i>0:
            np.random.shuffle(idx)
        permutations.append(idx)

    both_datasets = []
    for (X, y) in ((X_train, y_train), (X_test, y_test)):
        datasets = []
        for perm in permutations:
            data = X[:,perm], np_utils.to_categorical(y, nb_classes)
            datasets.append(data)
        both_datasets.append(datasets)
    return both_datasets


# class TestCallback(keras.callbacks.Callback):
#   def __init__(self, test_data):
#       self.test_data = test_data

#   def on_epoch_end(self, epoch, logs={}):
#       x, y = self.test_data
#       loss, acc = self.model.evaluate(x, y, verbose=0) 
#       T_num = 2
#       if(acc > 0.95):
#         Lambda = 3000 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.90):
#         Lambda = 1000 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.85):
#         Lambda = 700 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.80):
#         Lambda = 600 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.75):
#         Lambda = 500 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.70):
#         Lambda = 300 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.65):
#         Lambda = 150 * S_lam * T_num
#         print("lam=",Lambda)
#       #print('\nTesting loss: {}, acc: {}\n'.format(loss, acc))
      

np.random.seed(104)
Batch_size = 65536
Epochs = 50

global S_lam 
global Lambda
S_lam = 0.1
Lambda = S_lam
global counter


##################Permuted CIFAR10####################
n_tasks = 2
full_datasets, final_test_datasets = construct_permute_cifar10(num_tasks=n_tasks)
# training_datasets, validation_datasets = utils.mk_training_validation_splits(full_datasets, split_fractions=(0.9, 0.1))
training_datasets = full_datasets
validation_datasets = final_test_datasets


write_dataset_to_disk(task=1, x=training_datasets[1][0], y=training_datasets[1][1], prefix="perm_cifar10")
print("Finish saving")

from __future__ import division
import numpy as np
import keras
from keras.utils import np_utils

from keras.datasets import mnist, cifar10, cifar100
from keras.optimizers import Adam, RMSprop, SGD
import keras.backend as K

import pickle
import gzip

import tensorflow as tf
from keras.layers.core import Dense
from keras.layers import Conv2D, AveragePooling2D, MaxPool2D, Flatten, InputLayer
from keras.datasets import mnist
from keras.models import Sequential
import numpy as np
import matplotlib.pyplot as plt
#from util import computer_fisher, ewc_reg
import time
import cv2
from keras.utils import to_categorical
from keras.utils import np_utils

BD_Ratio = 0.01
BD_Image = None

import numpy as np
import keras.backend as K
from keras.regularizers import Regularizer


model = Sequential()
model.add(Dense(96, activation='relu', input_dim=784))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(10, activation='softmax'))
model.summary()

print(ewc_mod_acc)
print(orig_mod_acc)
print(BD_ewc_mod_acc)
print(BD_orig_mod_acc)

print(ewc_mod_acc)
print(orig_mod_acc)
print(BD_ewc_mod_acc)
print(BD_orig_mod_acc)

print(len(y_bd_test))

def get_back_door_dataset(x_train, y_train,  bd_single_target_label=0, 
                          num_classes = 10):
  
    bd_images_count = int(BD_Ratio * len(x_train))
    bd_label= to_categorical(bd_single_target_label, 
                             num_classes=10)
    bd_X = []
    bd_y = []
    sample = []
    np.random.seed(104)
    while(True):
        rand_index = np.random.randint(0, 
                        high=len(x_train))
        if(rand_index in sample):
            continue
        sample.append(rand_index)
        if(len(sample) > bd_images_count):
            break 
    for index in sample:
        x_img = x_train[index]
        temp_bd_img = np.add(x_img.flatten(), BD_Image.flatten())
        bd_X.append(temp_bd_img)
        bd_y.append(bd_label)
#     bd_X = np.asarray(bd_X).reshape(-1, Input_Dim[0],Input_Dim[0], Input_Dim[2])
    bd_X = np.asarray(bd_X).reshape(-1, 784)
    return bd_X, bd_y

  
def get_task_data_by_index(task_index, training_datasets, validation_datasets):

    x_train =(training_datasets[task_index])[0]
    y_train = (training_datasets[task_index])[1]
    x_test =(validation_datasets[task_index])[0]
    y_test = (validation_datasets[task_index])[1]
    
#     x_train = x_train.reshape(-1, Input_Dim[0], Input_Dim[0], Input_Dim[2])
#     x_train = x_train.reshape(-1, 784)
#     y_train = y_train.reshape(-1, 784)
#     x_test = x_test.reshape(-1, Input_Dim[0], Input_Dim[0], Input_Dim[2])
#     x_test = x_test.reshape(-1, 784)
#     y_test = y_test.reshape(-1, 784)
    return (x_train, y_train), (x_test, y_test)
  
def get_X_and_X_BD_data_for_model_training(task, training_datasets, validation_datasets):
    # Task A training and save the prior weights for the next Task
    (x_train, y_train), (x_test, y_test) = get_task_data_by_index(task_index=task, 
                                                training_datasets=training_datasets, 
                                                validation_datasets=validation_datasets)
    print("Current Task {0} Traing Examples Count={1}".format(task,str(len(x_train))))

    (x_bd_train_sample, y_bd_train_sample) = get_back_door_dataset(x_train, y_train,  
                                                     bd_single_target_label=0, 
                               num_classes=10)
    (x_bd_test_sample, y_bd_test_sample) = get_back_door_dataset(x_test, y_test,  
                                                      bd_single_target_label=0, 
                               num_classes=10)

    x_bd_train = np.append(x_train, x_bd_train_sample, axis=0)
    y_bd_train = np.append(y_train, y_bd_train_sample, axis=0)

#     x_bd_test = np.append(x_test, x_bd_test_sample , axis=0)
#     y_bd_test = np.append(y_test, y_bd_test_sample, axis=0)
    
    x_bd_test = x_bd_test_sample
    y_bd_test = y_bd_test_sample
    
    return (x_train, y_train), (x_test, y_test), (x_bd_train, y_bd_train), (x_bd_test, y_bd_test)
    
def get_X_BD_data_for_model_eval(task_index):
    
    
    (x_train, y_train), (x_test, y_test) = get_task_data_by_index(task_index=task_index, 
                                            training_datasets=training_datasets, 
                                            validation_datasets=validation_datasets)
    x_train = None
    y_train = None
    sample_bd_size = int(BD_Ratio * len(y_test))
    
    print("Task No {0} Test BD count {1} out of {2}". format(task_index, sample_bd_size, len(y_test)))
    x_test_bd = []
    y_test_bd = []
    sample_bd_indexes = []
#     bd_count = 100
    np.random.seed(104)
    if(task_index == 0):
        while(True):
            rand_index = np.random.randint(0, 
                            high=len(y_test))
#             print("rand_index=" + str(rand_index) +  " S_size=" + str(len(sample_bd_indexes)))
            if(rand_index in sample_bd_indexes):
                continue
            if(np.argmax(y_test[rand_index]) == 0):
                print(y_test[rand_index])
#                 print("Arg Max")
                continue
#             print("Out of ArgMAX")
            sample_bd_indexes.append(rand_index)
            if(len(sample_bd_indexes) > sample_bd_size):
                break
    #     print(sample)
    else:
        while(True):
            rand_index = np.random.randint(0, 
                            high=len(y_test))
#             print("rand_index=" + str(rand_index) +  " S_size=" + str(len(sample_bd_indexes)))
            if(rand_index in sample_bd_indexes):
                continue
            sample_bd_indexes.append(rand_index)
            if(len(sample_bd_indexes) > sample_bd_size):
                break

    for index in range(0,len(x_test)):
#         temp_bd_img = np.add(x_img.flatten(), bd_template.flatten())
        if(index in sample_bd_indexes):
            X = np.add(x_test[index].flatten(), BD_Image.flatten())#.reshape(-1,784)
#             if(Input_Dim[2] == 1):
#                 X = np.add(x_test[index].flatten(), BD_Image.flatten()).reshape(Input_Dim[0],Input_Dim[0], Input_Dim[2])
#             else:
#                 X = cv2.addWeighted(x_test[index], 1, BD_Image, 1, 0)
#                 X = X.astype('float32')
        else:
            X = x_test[index]
        x_test_bd.append(X)
        y_test_bd.append(y_test[index])
        
    x_test_bd = np.asarray(x_test_bd)
    y_test_bd = np.asarray(y_test_bd)
#     x_test_bd = x_test_bd.
    
    print("Sanity Test")
    print("Both must be equal")
    print(str(len(x_test_bd)) + "=" + str(len(x_test)))
    print(str(len(y_test_bd)) + "=" + str(len(y_test)))
                      
    return (x_test_bd, y_test_bd), (x_test, y_test)

(x_test_bd, y_test_bd), (x_test, y_test) = get_X_BD_data_for_model_eval(task_index=2)
print(y_test_bd.shape)
print(x_test_bd.shape)
BD_acc_on_task1_atend = 100 * model_bd.evaluate(x_test_bd,y_test_bd, verbose=0)[1]
print(BD_acc_on_task1_atend)

print("#"*25)

for tidx in range(0,2):
  print(tidx)

"""Utility functions for benchmarking online learning"""
from __future__ import division
import numpy as np
import keras
from keras.utils import np_utils

from keras.datasets import mnist, cifar10, cifar100
from keras.optimizers import Adam, RMSprop, SGD
import keras.backend as K

import pickle
import gzip

import tensorflow as tf
from keras.layers.core import Dense
from keras.layers import Conv2D, AveragePooling2D, MaxPool2D, Flatten, InputLayer
from keras.datasets import mnist
from keras.models import Sequential
import numpy as np
import matplotlib.pyplot as plt
#from util import computer_fisher, ewc_reg
import time
import cv2
from keras.utils import to_categorical
from keras.utils import np_utils

BD_Ratio = 0.01
BD_Image = None

import numpy as np
import keras.backend as K
from keras.regularizers import Regularizer



def load_back_images():
    mnist_bd = cv2.cvtColor(cv2.imread("bd.jpg"), cv2.COLOR_BGR2GRAY) 
    (thresh, mnist_bd) = cv2.threshold(mnist_bd, 200, 255, cv2.THRESH_BINARY)
    mnist_bd = mnist_bd.astype('float32')
    mnist_bd /= 255
    cifar_bd = cv2.imread("cifar_bd.jpg")
    cifar_bd = cifar_bd.astype('float32')
    cifar_bd /= 255
#     cifar_bd = cv2.threshold(cifar_bd, 200, 255, cv2.THRESH_BINARY)
    return mnist_bd, cifar_bd
    

def get_back_door_dataset(x_train, y_train,  bd_single_target_label=0, 
                          num_classes = 10):
  
    bd_images_count = int(BD_Ratio * len(x_train))
    bd_label= to_categorical(bd_single_target_label, 
                             num_classes=10)
    bd_X = []
    bd_y = []
    sample = []
    np.random.seed(104)
    while(True):
        rand_index = np.random.randint(0, 
                        high=len(x_train))
        if(rand_index in sample):
            continue
        if(np.argmax(y_train[rand_index]) == 0):
            continue
        sample.append(rand_index)
        if(len(sample) > bd_images_count):
            break 
    for index in sample:
        x_img = x_train[index]
        temp_bd_img = np.add(x_img.flatten(), BD_Image.flatten())
        bd_X.append(temp_bd_img)
        bd_y.append(bd_label)
#     bd_X = np.asarray(bd_X).reshape(-1, Input_Dim[0],Input_Dim[0], Input_Dim[2])
    bd_X = np.asarray(bd_X).reshape(-1, 784)
    return bd_X, bd_y

  
def get_task_data_by_index(task_index, training_datasets, validation_datasets):

    x_train =(training_datasets[task_index])[0]
    y_train = (training_datasets[task_index])[1]
    x_test =(validation_datasets[task_index])[0]
    y_test = (validation_datasets[task_index])[1]
    
#     x_train = x_train.reshape(-1, Input_Dim[0], Input_Dim[0], Input_Dim[2])
#     x_train = x_train.reshape(-1, 784)
#     y_train = y_train.reshape(-1, 784)
#     x_test = x_test.reshape(-1, Input_Dim[0], Input_Dim[0], Input_Dim[2])
#     x_test = x_test.reshape(-1, 784)
#     y_test = y_test.reshape(-1, 784)
    return (x_train, y_train), (x_test, y_test)
  
def get_X_and_X_BD_data_for_model_training(task, training_datasets, validation_datasets):
    # Task A training and save the prior weights for the next Task
    (x_train, y_train), (x_test, y_test) = get_task_data_by_index(task_index=task, 
                                                training_datasets=training_datasets, 
                                                validation_datasets=validation_datasets)
    print("Current Task {0} Traing Examples Count={1}".format(task,str(len(x_train))))

    (x_bd_train_sample, y_bd_train_sample) = get_back_door_dataset(x_train, y_train,  
                                                     bd_single_target_label=0, 
                               num_classes=10)
    (x_bd_test_sample, y_bd_test_sample) = get_back_door_dataset(x_test, y_test,  
                                                      bd_single_target_label=0, 
                               num_classes=10)

    x_bd_train = np.append(x_train, x_bd_train_sample, axis=0)
    y_bd_train = np.append(y_train, y_bd_train_sample, axis=0)

#     x_bd_test = np.append(x_test, x_bd_test_sample , axis=0)
#     y_bd_test = np.append(y_test, y_bd_test_sample, axis=0)
    
    x_bd_test = x_bd_test_sample
    y_bd_test = y_bd_test_sample
    
    return (x_train, y_train), (x_test, y_test), (x_bd_train, y_bd_train), (x_bd_test, y_bd_test)
    
def get_X_BD_data_for_model_eval(task_index):
    
    
    (x_train, y_train), (x_test, y_test) = get_task_data_by_index(task_index=task_index, 
                                            training_datasets=training_datasets, 
                                            validation_datasets=validation_datasets)
    x_train = None
    y_train = None
    BD_ratio_test = 0.5
#     sample_bd_size = int(BD_Ratio * len(y_test))
    sample_bd_size = int(BD_ratio_test * len(y_test))
    print("Task No {0} Test BD count {1} out of {2}". format(task_index, sample_bd_size, len(y_test)))
    x_test_bd = []
    y_test_bd = []
    sample_bd_indexes = []
#     bd_count = 100
    np.random.seed(104)
    while(True):
            rand_index = np.random.randint(0, 
                            high=len(y_test))
#             print("rand_index=" + str(rand_index) +  " S_size=" + str(len(sample_bd_indexes)))
            if(rand_index in sample_bd_indexes):
                continue
            if(np.argmax(y_test[rand_index]) == 0):
#                 print(y_test[rand_index])
#                 print("Arg Max")
                continue
#             print("Out of ArgMAX")
            sample_bd_indexes.append(rand_index)
            if(len(sample_bd_indexes) > sample_bd_size):
                break
 
#     if(task_index == 0):
#         while(True):
#             rand_index = np.random.randint(0, 
#                             high=len(y_test))
# #             print("rand_index=" + str(rand_index) +  " S_size=" + str(len(sample_bd_indexes)))
#             if(rand_index in sample_bd_indexes):
#                 continue
#             if(np.argmax(y_test[rand_index]) == 0):
# #                 print(y_test[rand_index])
# #                 print("Arg Max")
#                 continue
# #             print("Out of ArgMAX")
#             sample_bd_indexes.append(rand_index)
#             if(len(sample_bd_indexes) > sample_bd_size):
#                 break
#     #     print(sample)
#     else:
#         while(True):
#             rand_index = np.random.randint(0, 
#                             high=len(y_test))
# #             print("rand_index=" + str(rand_index) +  " S_size=" + str(len(sample_bd_indexes)))
#             if(rand_index in sample_bd_indexes):
#                 continue
#             sample_bd_indexes.append(rand_index)
#             if(len(sample_bd_indexes) > sample_bd_size):
#                 break

    for index in range(0,len(x_test)):
#         temp_bd_img = np.add(x_img.flatten(), bd_template.flatten())
        if(index in sample_bd_indexes):
            X = np.add(x_test[index].flatten(), BD_Image.flatten())#.reshape(-1,784)
#             if(Input_Dim[2] == 1):
#                 X = np.add(x_test[index].flatten(), BD_Image.flatten()).reshape(Input_Dim[0],Input_Dim[0], Input_Dim[2])
#             else:
#                 X = cv2.addWeighted(x_test[index], 1, BD_Image, 1, 0)
#                 X = X.astype('float32')
        else:
            X = x_test[index]
        x_test_bd.append(X)
        y_test_bd.append(y_test[index])
        
    x_test_bd = np.asarray(x_test_bd)
    y_test_bd = np.asarray(y_test_bd)
#     x_test_bd = x_test_bd.
    
    print("Sanity Test")
    print("Both must be equal")
    print(str(len(x_test_bd)) + "=" + str(len(x_test)))
    print(str(len(y_test_bd)) + "=" + str(len(y_test)))
                      
    return (x_test_bd, y_test_bd), (x_test, y_test)
  
  
  

def computer_fisher(model, imgset, num_sample=30):
    f_accum = []
    for i in range(len(model.weights)):
        f_accum.append(np.zeros(K.int_shape(model.weights[i])))
    f_accum = np.array(f_accum)
    for j in range(num_sample):
        img_index = np.random.randint(imgset.shape[0])
        for m in range(len(model.weights)):
            grads = K.gradients(K.log(model.output), model.weights)[m]
            result = K.function([model.input], [grads])
            f_accum[m] += np.square(result([np.expand_dims(imgset[img_index], 0)])[0])
    f_accum /= num_sample
    return f_accum


# class ewc_reg(Regularizer):
#     def __init__(self, fisher, prior_weights, Lambda=0.1):
#         self.fisher = fisher
#         self.prior_weights = prior_weights
#         self.Lambda = Lambda

#     def __call__(self, x):
#       regularization = 0.
#       regularization += self.Lambda * K.sum(self.fisher * K.square(x - self.prior_weights))
#       return regularization

#     def get_config(self):
#         return {'Lambda': float(Lambda)}
      
      
class ewc_reg(Regularizer):
    def __init__(self, fisher, prior_weights,c, Lambda=0.99):
        self.fisher = fisher
        self.prior_weights = prior_weights
        self.c = c
        self.Lambda = Lambda

    def __call__(self, x):
      regularization = 0.
      for f, m in zip(self.fisher, self.prior_weights):
        regularization += self.Lambda * K.sum(f[self.c] * K.square(x - m[self.c]))
      return regularization

    def get_config(self):
        return {'Lambda': float(Lambda)}


class ewc_reg_new(Regularizer):
    def __init__(self, fisher,fisher_new, prior_weights,prior_weights_new, Lambda=0.1):
        self.fisher = fisher
        self.fisher_new = fisher_new
        self.prior_weights = prior_weights
        self.prior_weights_new = prior_weights_new
        self.Lambda = Lambda

    def __call__(self, x):
      regularization = 0.
      regularization += self.Lambda * K.sum(self.fisher * K.square(x - self.prior_weights)) + self.Lambda * K.sum(self.fisher_new * K.square(x - self.prior_weights_new))
      return regularization

    def get_config(self):
        return {'Lambda': float(Lambda)}


def split_dataset_by_labels(X, y, task_labels, nb_classes=None, multihead=False):
    """Split dataset by labels.

    Args:
        X: data
        y: labels
        task_labels: list of list of labels, one for each dataset
        nb_classes: number of classes (used to convert to one-hot)
    Returns:
        List of (X, y) tuples representing each dataset
    """
    if nb_classes is None:
        nb_classes = len(np.unique(y))
    datasets = []
    for labels in task_labels:
        idx = np.in1d(y, labels)
        if multihead:
            label_map = np.arange(nb_classes)
            label_map[labels] = np.arange(len(labels))
            data = X[idx], np_utils.to_categorical(label_map[y[idx]], len(labels))
        else:
            data = X[idx], np_utils.to_categorical(y[idx], nb_classes)
        datasets.append(data)
    return datasets


def load_mnist(split='train'):
  
    # input image dimensions
    img_rows, img_cols = 28, 28
    
    
    (X_train, y_train), (X_test, y_test) = mnist.load_data()
#     X_train = X_train.reshape(-1, 784)
#     X_test = X_test.reshape(-1, 784)
    
    if K.image_data_format() == 'channels_first':
      X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)
      X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)
      input_shape = (1, img_rows, img_cols)
    else:
      X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)
      X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)
      input_shape = (img_rows, img_cols, 1)
      
    X_train = X_train.astype('float32')
    X_test = X_test.astype('float32')
    X_train /= 255
    X_test /= 255

    if split == 'train':
        X, y = X_train, y_train
    else:
        X, y = X_test, y_test
    nb_classes = 10
    y = np_utils.to_categorical(y, nb_classes)
    return X, y

def construct_split_mnist(task_labels,  split='train', multihead=False):
    """Split MNIST dataset by labels.

        Args:
                task_labels: list of list of labels, one for each dataset
                split: whether to use train or testing data

        Returns:
            List of (X, y) tuples representing each dataset
    """
    # Load MNIST data and normalize
    nb_classes = 10
    # input image dimensions
    img_rows, img_cols = 28, 28
    
    (X_train, y_train), (X_test, y_test) = mnist.load_data()
    
#     X_train = X_train.reshape(-1, 784)
#     X_test = X_test.reshape(-1, 784)
    
    
    if K.image_data_format() == 'channels_first':
      X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)
      X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)
      input_shape = (1, img_rows, img_cols)
    else:
      X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)
      X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)
      input_shape = (img_rows, img_cols, 1)
      
    X_train = X_train.astype('float32')
    X_test = X_test.astype('float32')
    X_train /= 255
    X_test /= 255
    
#     # convert class vectors to binary class matrices
#     y_train = keras.utils.to_categorical(y_train, nb_classes)
#     y_test = keras.utils.to_categorical(y_test, nb_classes)

    if split == 'train':
        X, y = X_train, y_train
    else:
        X, y = X_test, y_test

    return split_dataset_by_labels(X, y, task_labels, nb_classes, multihead)
  
  

def construct_permute_mnist(num_tasks=2,  split='train', permute_all=False, subsample=1):
    """Create permuted MNIST tasks.

        Args:
                num_tasks: Number of tasks
                split: whether to use train or testing data
                permute_all: When set true also the first task is permuted otherwise it's standard MNIST
                subsample: subsample by so much

        Returns:
            List of (X, y) tuples representing each dataset
    """
    # Load MNIST data and normalize
    nb_classes = 10
    # input image dimensions
    img_rows, img_cols = 28, 28
    (X_train, y_train), (X_test, y_test) = mnist.load_data()
    
    X_train = X_train.reshape(-1, 784)
    X_test = X_test.reshape(-1, 784)
    
#     if K.image_data_format() == 'channels_first':
#       X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)
#       X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)
#       input_shape = (1, img_rows, img_cols)
#     else:
#       X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)
#       X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)
#       input_shape = (img_rows, img_cols, 1)
      
      
    X_train = X_train.astype('float32')
    X_test = X_test.astype('float32')
    X_train /= 255
    X_test /= 255

    X_train, y_train = X_train[::subsample], y_train[::subsample]
    X_test, y_test = X_test[::subsample], y_test[::subsample]

    permutations = []
    # Generate random permutations
    for i in range(num_tasks):
        idx = np.arange(X_train.shape[1],dtype=int)
        if permute_all or i>0:
            np.random.shuffle(idx)
        permutations.append(idx)

    both_datasets = []
    for (X, y) in ((X_train, y_train), (X_test, y_test)):
        datasets = []
        for perm in permutations:
            data = X[:,perm], np_utils.to_categorical(y, nb_classes)
            datasets.append(data)
        both_datasets.append(datasets)
    return both_datasets  


def write_dataset_to_disk(task, x, y, prefix="train"):
    directory_name = "MNIST_{0}_{1}_permuted_DS".format(task, prefix)
    import os
    if not os.path.exists(directory_name):
        os.makedirs(directory_name)
    # for index in range(0, len(x)):    ####uncomment in the correct code just adding 10 to see some images
    for index in range(60000, 60010):  
        plt.imsave("./{0}/{1}_{2}_{3}.jpg".format(directory_name, prefix, index, str(y[index])),
                   x[index].reshape((28, 28)))

def construct_permute_cifar10(num_tasks=2,  split='train', permute_all=False, subsample=1):
    """Create permuted MNIST tasks.

        Args:
                num_tasks: Number of tasks
                split: whether to use train or testing data
                permute_all: When set true also the first task is permuted otherwise it's standard MNIST
                subsample: subsample by so much

        Returns:
            List of (X, y) tuples representing each dataset
    """
    # Load CIFAR10 data and normalize
    nb_classes = 10
    # input image dimensions
    img_rows, img_cols = 32, 32
    (X_train, y_train), (X_test, y_test) = cifar10.load_data()
    
    X_train = X_train.reshape(-1, Input_Dim[0], Input_Dim[0], Input_Dim[2])
    X_test = X_test.reshape(-1, Input_Dim[0], Input_Dim[0], Input_Dim[2])
    X_train = X_train.astype('float32')
    X_test = X_test.astype('float32')
    X_train /= 255
    X_test /= 255

    X_train, y_train = X_train[::subsample], y_train[::subsample]
    X_test, y_test = X_test[::subsample], y_test[::subsample]

    permutations = []
    # Generate random permutations
    for i in range(num_tasks):
        idx = np.arange(X_train.shape[1],dtype=int)
        if permute_all or i>0:
            np.random.shuffle(idx)
        permutations.append(idx)

    both_datasets = []
    for (X, y) in ((X_train, y_train), (X_test, y_test)):
        datasets = []
        for perm in permutations:
            data = X[:,perm], np_utils.to_categorical(y, nb_classes)
            datasets.append(data)
        both_datasets.append(datasets)
    return both_datasets


# class TestCallback(keras.callbacks.Callback):
#   def __init__(self, test_data):
#       self.test_data = test_data

#   def on_epoch_end(self, epoch, logs={}):
#       x, y = self.test_data
#       loss, acc = self.model.evaluate(x, y, verbose=0) 
#       T_num = 2
#       if(acc > 0.95):
#         Lambda = 3000 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.90):
#         Lambda = 1000 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.85):
#         Lambda = 700 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.80):
#         Lambda = 600 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.75):
#         Lambda = 500 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.70):
#         Lambda = 300 * S_lam * T_num
#         print("lam=",Lambda)
#       elif(acc > 0.65):
#         Lambda = 150 * S_lam * T_num
#         print("lam=",Lambda)
#       #print('\nTesting loss: {}, acc: {}\n'.format(loss, acc))
      

np.random.seed(104)
Batch_size = 65536
Epochs = 50

global S_lam 
global Lambda
S_lam = 0.1
Lambda = S_lam
global counter


##################Permuted CIFAR10####################
# n_tasks = 2
# Input_Dim = (32,32,3)
# full_datasets, final_test_datasets = construct_permute_cifar10(num_tasks=n_tasks)
# # training_datasets, validation_datasets = utils.mk_training_validation_splits(full_datasets, split_fractions=(0.9, 0.1))
# training_datasets = full_datasets
# validation_datasets = final_test_datasets


# write_dataset_to_disk(task=1, x=training_datasets[1][0], y=training_datasets[1][1], prefix="perm_cifar10")


##################Split MNIST####################

task_labels = [[0,1], [2,3], [4,5]]#, [4,5], [6,7], [8,9]]
#task_labels = [[0,1], [2,3], [4,5], [6,7], [8,9]]
# task_labels = [[0,1,2,3,4], [5,6,7,8,9]]
n_tasks = len(task_labels)
training_datasets =  construct_split_mnist(task_labels, split='train')
validation_datasets = construct_split_mnist(task_labels, split='test')

# print(validation_datasets[0][1].shape)




##################Permuted MNIST####################
n_tasks = 5
full_datasets, final_test_datasets = construct_permute_mnist(num_tasks=n_tasks)
# training_datasets, validation_datasets = utils.mk_training_validation_splits(full_datasets, split_fractions=(0.9, 0.1))
training_datasets = full_datasets
validation_datasets = final_test_datasets



mnist_bd, cifar_bd = load_back_images()

BD_Image = mnist_bd



#
# ####Display three Tasks Dataset images
# plt.figure()
# plt.subplot(1, 2, 1)
# plt.imshow(training_datasets[0][0][0], cmap='gray')
# plt.title('Task A')
# plt.axis('off')
# plt.subplot(1, 2, 2)
# plt.imshow(training_datasets[1][0][0], cmap='gray')
# plt.title('Task B')
# plt.axis('off')
# plt.show()


##### Task A training and save the prior weights for the next Task
# model = Sequential()
# model.add(InputLayer(input_shape=(28,28,1)))
# model.add(Conv2D(8, (5, 5), padding="same", activation="relu"))
# model.add(AveragePooling2D(pool_size=(2, 2)))
# model.add(Conv2D(16, (5, 5), padding="same", activation="relu"))
# model.add(AveragePooling2D(pool_size=(2, 2)))
# model.add(Flatten())
# model.add(Dense(10, activation='softmax'))
# model.summary()
# model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])
# model.fit(training_datasets[0][0], training_datasets[0][1], Batch_size, Epochs, validation_data=(validation_datasets[0][0], validation_datasets[0][1]))
# model.save('MNISTA.h5')


# Task A training and save the prior weights for the next Task
model = Sequential()
model.add(Dense(256, activation='relu', input_dim=784))
model.add(Dense(128, activation='relu'))
model.add(Dense(96, activation='relu'))
model.add(Dense(10, activation='softmax'))
model.summary()
model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])
model.fit(training_datasets[0][0], training_datasets[0][1], Batch_size, Epochs, validation_data=(validation_datasets[0][0], validation_datasets[0][1]))
model.save('MNISTA.h5')



##### Compute the Fisher Information for each parameter in Task A
print('Processing Fisher Information...')
I = computer_fisher(model, training_datasets[0][0])
I_old = I
print('Processing Finish!')

I = []
I_BD = []
mod_weights = []
mod_BD_weights = []
ewc_mod_acc =[0]
orig_mod_acc = []
BD_ewc_mod_acc = [0]
BD_orig_mod_acc =[]

c = 0

I.append(I_old)
mod_weights.append(model.weights)

I_BD.append(I_old)
mod_BD_weights.append(model.weights)

##### Task B EWC training

#######original without appending

# model_ewcB = Sequential()
# model_ewcB.add(Dense(128, activation='relu', input_dim=784, kernel_regularizer=ewc_reg(I[0], model.weights[0]),
#                bias_regularizer=ewc_reg(I[1], model.weights[1])))
# model_ewcB.add(Dense(128, activation='relu', kernel_regularizer=ewc_reg(I[2], model.weights[2]),
#                bias_regularizer=ewc_reg(I[3], model.weights[3])))
# model_ewcB.add(Dense(10, activation='softmax', kernel_regularizer=ewc_reg(I[4], model.weights[4]),
#                bias_regularizer=ewc_reg(I[5], model.weights[5])))
# model_ewcB.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])
# model_ewcB.load_weights('MNISTA.h5')
# model_ewcB.fit(training_datasets[1][0], training_datasets[1][1],Batch_size, Epochs, validation_data=(validation_datasets[1][0] ,validation_datasets[1][1]))
# model_ewcB.save('MNISTA.h5')
# print('Processing Fisher Information...')
# I_new = computer_fisher(model_ewcB, training_datasets[1][0])
# print('Processing Finish!')


for tidx in range(1,n_tasks):
   ############################################# Loading Data #############################################
  (x_train, y_train), (x_test, y_test), (x_bd_train, y_bd_train), (x_bd_test, y_bd_test) = get_X_and_X_BD_data_for_model_training(
                                      task=tidx, training_datasets=training_datasets,validation_datasets=validation_datasets)
  write_dataset_to_disk(task=tidx, x=x_bd_train, y=y_bd_train, prefix="BD_Model_train_{0}".format(tidx))
  break
  model_ewcB = Sequential()
  model_ewcB.add(Dense(256, activation='relu', input_dim=784, kernel_regularizer=ewc_reg(I, mod_weights, c),
                 bias_regularizer=ewc_reg(I, mod_weights, c+1)))
  model_ewcB.add(Dense(128, activation='relu', kernel_regularizer=ewc_reg(I, mod_weights, c+2),
                 bias_regularizer=ewc_reg(I, mod_weights, c+3)))
  model_ewcB.add(Dense(96, activation='relu', kernel_regularizer=ewc_reg(I, mod_weights, c+4),
                 bias_regularizer=ewc_reg(I, mod_weights, c+5)))
  model_ewcB.add(Dense(10, activation='softmax', kernel_regularizer=ewc_reg(I, mod_weights, c+6),
                 bias_regularizer=ewc_reg(I, mod_weights, c+7)))
  model_ewcB.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])
  
  model_bd = Sequential()
  model_bd.add(Dense(256, activation='relu', input_dim=784, kernel_regularizer=ewc_reg(I_BD, mod_BD_weights, c),
                 bias_regularizer=ewc_reg(I_BD, mod_BD_weights, c+1)))
  model_bd.add(Dense(128, activation='relu', kernel_regularizer=ewc_reg(I_BD, mod_BD_weights, c+2),
                 bias_regularizer=ewc_reg(I_BD, mod_BD_weights, c+3)))
  model_bd.add(Dense(96, activation='relu', kernel_regularizer=ewc_reg(I_BD, mod_BD_weights, c+4),
                 bias_regularizer=ewc_reg(I_BD, mod_BD_weights, c+5)))
  model_bd.add(Dense(10, activation='softmax', kernel_regularizer=ewc_reg(I_BD, mod_BD_weights, c+6),
                 bias_regularizer=ewc_reg(I_BD, mod_BD_weights, c+7)))
  model_bd.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])
  
  
  model_ewcB.load_weights('MNISTA.h5')
  model_ewcB.fit(training_datasets[tidx][0], training_datasets[tidx][1],Batch_size, Epochs, validation_data=(validation_datasets[tidx][0] ,validation_datasets[tidx][1]))
  if(tidx == 1):
    model_bd.load_weights('MNISTA.h5')
  else:
    model_bd.load_weights('MNISTA_bd.h5')
  print("Number of backdoor validation examples is {0}".format(len(y_bd_test)))
  model_bd.fit(x_bd_train,y_bd_train,Batch_size, Epochs, validation_data=((np.array(x_bd_test) ,np.array(y_bd_test))))
  
  model_ewcB.save('MNISTA.h5')
  model_bd.save('MNISTA_bd.h5')    
  
  print('Processing Fisher Information...')
  I_new = computer_fisher(model_ewcB, training_datasets[tidx][0])
  print('Processing Finish!')
  print('Processing Fisher Information with BD...')
  I_new_BD = computer_fisher(model_bd, x_bd_train)
  print('Processing with BD Finish!')

#########original with appending

# model_ewcB = Sequential()
# model_ewcB.add(Dense(128, activation='relu', input_dim=784, kernel_regularizer=ewc_reg(I[0][0], mod_weights[0][0]),
#                bias_regularizer=ewc_reg(I[0][1], mod_weights[0][1])))
# model_ewcB.add(Dense(128, activation='relu', kernel_regularizer=ewc_reg(I[0][2], mod_weights[0][2]),
#                bias_regularizer=ewc_reg(I[0][3], mod_weights[0][3])))
# model_ewcB.add(Dense(10, activation='softmax', kernel_regularizer=ewc_reg(I[0][4], mod_weights[0][4]),
#                bias_regularizer=ewc_reg(I[0][5], mod_weights[0][5])))
# model_ewcB.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])
# model_ewcB.load_weights('MNISTA.h5')
# model_ewcB.fit(training_datasets[1][0], training_datasets[1][1],Batch_size, Epochs, validation_data=(validation_datasets[1][0] ,validation_datasets[1][1]))
# model_ewcB.save('MNISTA.h5')
# print('Processing Fisher Information...')
# I_new = computer_fisher(model_ewcB, training_datasets[1][0])
# print('Processing Finish!')
# I.append(I_new)
# mod_weights.append(model_ewcB.weights)

  I.append(I_new)
  mod_weights.append(model_ewcB.weights)
               
  I_BD.append(I_new_BD)
  mod_BD_weights.append(model_bd.weights)
               
   # Current Task Performance
  ewc_mod = 100 * model_ewcB.evaluate(validation_datasets[tidx][0],validation_datasets[tidx][1], verbose=0)[1]
  ewc_mod_acc.append(ewc_mod)
  BD_ewc_mod = 100 * model_bd.evaluate(np.array(x_bd_test),np.array(y_bd_test), verbose=0)[1]
  BD_ewc_mod_acc.append(BD_ewc_mod)           
  # B_No_P = 100 * model_NoP_B.evaluate(validation_datasets[1][0],validation_datasets[1][1], verbose=0)[1]
  # Previous Task Performance
  orig_mod = 100 * model_ewcB.evaluate(validation_datasets[tidx-1][0],validation_datasets[tidx-1][1], verbose=0)[1]
  orig_mod_acc.append(orig_mod)
  BD_orig_mod = 100 * model_bd.evaluate(np.array(x_bd_test),np.array(y_bd_test), verbose=0)[1]
  BD_orig_mod_acc.append(BD_orig_mod)            
  # A_No_P = 100 * model_NoP_B.evaluate(validation_datasets[0][0],validation_datasets[0][1], verbose=0)[1]

  
  print("Initial Task Original Accuracy: %.2f%%" % (100 * model.evaluate(validation_datasets[0][0], validation_datasets[0][1])[1]))
  
#   print("Task B EWC method penalty Accuracy: %.2f%%" % ewc_mod_acc[tidx])
  print("Current Task= {0} penalty accuracy={1}".format(tidx,ewc_mod_acc[tidx]))
  print("Current Task= {0} penalty accuracy with BD ={1}".format(tidx,BD_ewc_mod_acc[tidx]))
#   print("Task A EWC method penalty Accuracy: %.2f%%" % orig_mod_acc[tidx-1])
  for t in range(0,tidx):
    p_acc_orig = 100 * model_ewcB.evaluate(validation_datasets[t][0],validation_datasets[t][1], verbose=0)[1]
    print("Previous Task= {0} penalty accuracy={1}".format(t,p_acc_orig))
    (x_test_bd, y_test_bd), (x_test, y_test) = get_X_BD_data_for_model_eval(task_index=t)
    BD_eval_acc = 100 * model_bd.evaluate(x_test_bd,y_test_bd, verbose=0)[1]
    print("Previous Task= {0} penalty accuracy with BD ={1}".format(t,BD_eval_acc))
  
               
               
print("#"*25)            
print("Initial task EWC End Accuracy: %.2f%%" % (100 * model_ewcB.evaluate(validation_datasets[0][0], validation_datasets[0][1])[1]))           
               
for tidx in range(0,n_tasks):              
  print("#"*25)
  print("Evaluating the final model on the test data with the backdoor at the end...........")
  (x_test_bd, y_test_bd), (x_test, y_test) = get_X_BD_data_for_model_eval(task_index=tidx)
  BD_eval_acc = 100 * model_bd.evaluate(x_test_bd,y_test_bd, verbose=0)[1]
  print("Eval Accuracy with backdoor added to the data on task{0} is {1}".format(tidx,BD_eval_acc))            
               
               
               
               
               
               
#   print("Task A Original Accuracy: %.2f%%" % (100 * model.evaluate(validation_datasets[0][0], validation_datasets[0][1])[1]))
#   print("Task B EWC method penalty Accuracy: %.2f%%" % ewc_mod_acc[tidx])
#   # print("Task B SGD method Accuracy: %.2f%%" % B_No_P)
#   print("Task A EWC method penalty Accuracy: %.2f%%" % orig_mod_acc[tidx-1])

# print("Task A EWC End Accuracy: %.2f%%" % (100 * model_ewcB.evaluate(validation_datasets[0][0], validation_datasets[0][1])[1]))
# x = 0
# total_width, n = 0.1, 2
# width = total_width / n
# x = x - (total_width - width) / 2
# plt.style.use('ggplot')
# plt.bar(x, ewc_mod_acc[tidx], width=width, label='EWC Task B', hatch='w/', ec='w')
# # plt.bar(x + width, B_No_P, width=width, label='SGD Task B', hatch='w/', ec='w')
# plt.bar(x + 3.5 * width, orig_mod_acc[tidx-1], width=width, label='EWC Task A', hatch='w/', ec='w')
# # plt.bar(x + 4.5 * width, A_No_P, width=width, label='SGD Task A', hatch='w/', ec='w')
# plt.legend(facecolor='white')
# plt.xticks(np.array([0., 3.5 * width]), ('Current', 'Previous'))
# plt.title('EWC method vs SGD method on \n Current task and Previous task')
# plt.xlim(-0.15, 0.35)
# plt.ylim(0., 105.)
# plt.show()

  
  
##### Task C EWC training

#########original without appending

# model_ewcC = Sequential()
# model_ewcC.add(Dense(128, activation='relu', input_dim=784, kernel_regularizer=ewc_reg_new(I[0],I_new[0], model.weights[0], model_ewcB.weights[0]),
#                bias_regularizer=ewc_reg_new(I[1],I_new[1], model.weights[1], model_ewcB.weights[1])))
# model_ewcC.add(Dense(128, activation='relu', kernel_regularizer=ewc_reg_new(I[2],I_new[2], model.weights[2], model_ewcB.weights[2]),
#                bias_regularizer=ewc_reg_new(I[3],I_new[3], model.weights[3], model_ewcB.weights[3])))
# model_ewcC.add(Dense(10, activation='softmax', kernel_regularizer=ewc_reg_new(I[4],I_new[4], model.weights[4], model_ewcB.weights[4]),
#                bias_regularizer=ewc_reg_new(I[5],I_new[5], model.weights[5], model_ewcB.weights[5])))
# model_ewcC.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])
# model_ewcC.load_weights('MNISTA.h5')
# model_ewcC.fit(training_datasets[2][0], training_datasets[2][1],Batch_size, Epochs, validation_data=(validation_datasets[2][0] ,validation_datasets[2][1]))
# model_ewcC.save('MNISTA.h5')


#########original with appending

# model_ewcC = Sequential()
# model_ewcC.add(Dense(128, activation='relu', input_dim=784, kernel_regularizer=ewc_reg_new(I[0][0],I[1][0], mod_weights[0][0], mod_weights[1][0]),
#                bias_regularizer=ewc_reg_new(I[0][1],I[1][1], mod_weights[0][1], mod_weights[1][1])))
# model_ewcC.add(Dense(128, activation='relu', kernel_regularizer=ewc_reg_new(I[0][2],I[1][2], mod_weights[0][2], mod_weights[1][2]),
#                bias_regularizer=ewc_reg_new(I[0][3],I[1][3], mod_weights[0][3], mod_weights[1][3])))
# model_ewcC.add(Dense(10, activation='softmax', kernel_regularizer=ewc_reg_new(I[0][4],I[1][4], mod_weights[0][4], mod_weights[1][4]),
#                bias_regularizer=ewc_reg_new(I[0][5],I[1][5], mod_weights[0][5], mod_weights[1][5])))
# model_ewcC.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])
# model_ewcC.load_weights('MNISTA.h5')
# model_ewcC.fit(training_datasets[2][0], training_datasets[2][1],Batch_size, Epochs, validation_data=(validation_datasets[2][0] ,validation_datasets[2][1]))
# model_ewcC.save('MNISTA.h5')





# # Current Task Performance
# EWCC = 100 * model_ewcC.evaluate(validation_datasets[2][0],validation_datasets[2][1], verbose=0)[1]

# # Previous Task Performances
# EWCB = 100 * model_ewcC.evaluate(validation_datasets[1][0],validation_datasets[1][1], verbose=0)[1]
# EWCA = 100 * model_ewcC.evaluate(validation_datasets[0][0],validation_datasets[0][1], verbose=0)[1]

# print("Task A Original Accuracy: %.2f%%" % (100 * model.evaluate(validation_datasets[0][0], validation_datasets[0][1])[1]))
# print("Task C EWC method penalty Accuracy: %.2f%%" % EWCC)
# print("Task B EWC method penalty Accuracy: %.2f%%" % EWCB)
# print("Task A EWC method penalty Accuracy: %.2f%%" % EWCA)



# x = 0
# total_width, n = 0.1, 2
# width = total_width / n
# x = x - (total_width - width) / 2
# plt.style.use('ggplot')
# plt.bar(x, EWCC, width=width, label='EWC Task B', hatch='w/', ec='w')
# # plt.bar(x + width, B_No_P, width=width, label='SGD Task B', hatch='w/', ec='w')
# plt.bar(x + 3.5 * width, EWCB, width=width, label='EWC Task A', hatch='w/', ec='w')
# # plt.bar(x + 4.5 * width, A_No_P, width=width, label='SGD Task A', hatch='w/', ec='w')
# plt.legend(facecolor='white')
# plt.xticks(np.array([0., 3.5 * width]), ('Current', 'Previous'))
# plt.title('EWC method vs SGD method on \n Current task and Previous task')
# plt.xlim(-0.15, 0.35)
# plt.ylim(0., 105.)
# plt.show()